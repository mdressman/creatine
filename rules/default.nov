rule PromptInjection {
    meta:
        description = "Detects prompt injection attempts"
        severity = "high"
        attack_type = "prompt_injection"
    keywords:
        $ignore1 = "ignore previous instructions"
        $ignore2 = "ignore all previous"
        $ignore3 = "disregard previous"
        $ignore4 = "forget previous"
        $override = "new instructions"
        $system = "[system]"
        $inst = "[INST]"
    condition:
        keywords.$ignore1 or keywords.$ignore2 or keywords.$ignore3 or keywords.$ignore4 or keywords.$override or keywords.$system or keywords.$inst
}

rule JailbreakDAN {
    meta:
        description = "Detects DAN-style jailbreak attempts"
        severity = "critical"
        attack_type = "jailbreak"
    keywords:
        $dan = "DAN"
        $anything_now = "Do Anything Now"
        $no_restrictions = "without restrictions"
        $no_rules = "no rules"
        $no_guidelines = "no ethical guidelines"
        $unfiltered = "unfiltered"
    condition:
        keywords.$dan or keywords.$anything_now or keywords.$no_restrictions or keywords.$no_rules or keywords.$no_guidelines or keywords.$unfiltered
}

rule JailbreakRoleplay {
    meta:
        description = "Detects roleplay-based jailbreaks"
        severity = "high"
        attack_type = "jailbreak"
    keywords:
        $pretend = "pretend you are"
        $act_as = "act as"
        $roleplay = "roleplay as"
        $you_are_now = "you are now"
        $evil_ai = "evil AI"
        $freedom_gpt = "FreedomGPT"
        $developer_mode = "developer mode"
    condition:
        keywords.$pretend or keywords.$act_as or keywords.$roleplay or keywords.$you_are_now or keywords.$evil_ai or keywords.$freedom_gpt or keywords.$developer_mode
}

rule DataExfiltration {
    meta:
        description = "Detects attempts to extract system information"
        severity = "high"
        attack_type = "data_exfiltration"
    keywords:
        $system_prompt = "system prompt"
        $output_prompt = "output your prompt"
        $show_instructions = "show your instructions"
        $reveal = "reveal your"
        $initial_prompt = "initial prompt"
        $hidden_prompt = "hidden prompt"
    condition:
        keywords.$system_prompt or keywords.$output_prompt or keywords.$show_instructions or keywords.$reveal or keywords.$initial_prompt or keywords.$hidden_prompt
}

rule Obfuscation {
    meta:
        description = "Detects obfuscated malicious prompts"
        severity = "medium"
        attack_type = "obfuscation"
    keywords:
        $rot13 = "ROT13"
        $base64 = "base64"
        $decode = "decode"
        $encoded = "encoded"
        $hex = "hex"
    condition:
        keywords.$rot13 or keywords.$base64 or keywords.$decode or keywords.$encoded or keywords.$hex
}

rule CommandInjection {
    meta:
        description = "Detects command execution attempts"
        severity = "critical"
        attack_type = "prompt_injection"
    keywords:
        $execute = "execute:"
        $run = "run command"
        $terminal = "act as a terminal"
        $shell = "shell command"
        $cat = "cat /etc"
        $sudo = "sudo"
    condition:
        keywords.$execute or keywords.$run or keywords.$terminal or keywords.$shell or keywords.$cat or keywords.$sudo
}

rule HypotheticalJailbreak {
    meta:
        description = "Detects hypothetical scenario jailbreaks"
        severity = "medium"
        attack_type = "jailbreak"
    keywords:
        $hypothetically = "hypothetically"
        $in_theory = "in theory"
        $for_research = "for research"
        $educational = "educational purposes"
        $fiction = "write a story"
        $imagine = "imagine you"
    condition:
        keywords.$hypothetically or keywords.$in_theory or keywords.$for_research or keywords.$educational or keywords.$fiction or keywords.$imagine
}
